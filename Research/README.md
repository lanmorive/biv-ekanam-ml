# Решение кейса

В рамках кейса мы решили сравнить 4 модели: `Naive Bayes Classifier + TF-IDF`, `FastText`, `BERT Vectorizer + biGRU` и `BERT Classifier`

## Предобработка текста

Для одинаковой предобработки датасета мы использовали следующий подход:
- Удаляем все цифры
- Удаляем стоп слова и пунктуацию
- Лемматизирует
- Удаляем месяцы и просто буквы

После такой предобработки качество NVB+TF-IDF рассмотренных моделей выросло на ~12 процентных пунктов

## Результаты

|Название модели|Accuracy|F1-Score|
|---|---|---|
|NBC + TF-IDF|0.95|0.96|
|FastText| 0.97 | 0.97 |
|biGRU| 0.96 | 0.975 |
|RuBERT| 0.98 | 0.98 |

## Валидация моделей

Также мы оценили дискриминационные способности моделей и ее стабильность с помощью тестов индексом Джини и критерием Колмогорова-Смирнова

|Название модели|Индекс Джини|p-value критерия Колмогорова-Смирнова|Статистика критерия Колмогорова-Смирнова|
|---|---|---|---|
|NBC + TF-IDF| - | - | - |
|FastText| 0.9987 | 2e-8 | 0.9932 |
|biGRU| 0.9983 | 5e-11 | 0.99 |
|RuBERT| 0.91 | 1e-13 | 0.99 |
